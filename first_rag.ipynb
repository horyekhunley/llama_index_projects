{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU llama-index-llms-huggingface llama-index-llms-huggingface-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.llama_dataset import download_llama_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "hf_token = getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mahbub/Documents/dev/llama_index_projects/.conda/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid (permission: fineGrained).\n",
      "\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
      "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
      "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
      "\n",
      "git config --global credential.helper store\n",
      "\n",
      "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n",
      "Token has not been saved to git credential helper.\n",
      "Your token has been saved to /home/mahbub/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(token=hf_token, add_to_git_credential=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_dataset, documents = download_llama_dataset(\"BlockchainSolanaDataset\", \"./data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference_answer</th>\n",
       "      <th>reference_answer_by</th>\n",
       "      <th>query_by</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What are the key issues preventing the wide ad...</td>\n",
       "      <td>[From Bitcoin to Solana – Innovating Blockchai...</td>\n",
       "      <td>The key issues preventing the wide adoption of...</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How does blockchain technology provide data se...</td>\n",
       "      <td>[From Bitcoin to Solana – Innovating Blockchai...</td>\n",
       "      <td>Blockchain technology provides data security a...</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the projected growth rate of the block...</td>\n",
       "      <td>[2 \\n \\nchain market size is expected to grow ...</td>\n",
       "      <td>The projected growth rate of the blockchain ma...</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  What are the key issues preventing the wide ad...   \n",
       "1  How does blockchain technology provide data se...   \n",
       "2  What is the projected growth rate of the block...   \n",
       "\n",
       "                                  reference_contexts  \\\n",
       "0  [From Bitcoin to Solana – Innovating Blockchai...   \n",
       "1  [From Bitcoin to Solana – Innovating Blockchai...   \n",
       "2  [2 \\n \\nchain market size is expected to grow ...   \n",
       "\n",
       "                                    reference_answer reference_answer_by  \\\n",
       "0  The key issues preventing the wide adoption of...  ai (gpt-3.5-turbo)   \n",
       "1  Blockchain technology provides data security a...  ai (gpt-3.5-turbo)   \n",
       "2  The projected growth rate of the blockchain ma...  ai (gpt-3.5-turbo)   \n",
       "\n",
       "             query_by  \n",
       "0  ai (gpt-3.5-turbo)  \n",
       "1  ai (gpt-3.5-turbo)  \n",
       "2  ai (gpt-3.5-turbo)  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_dataset.to_pandas()[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.llms.huggingface_api import HuggingFaceInferenceAPI\n",
    "\n",
    "ollama_llm = Ollama(model=\"phi3\", request_timeout=60.0, temperature=0)\n",
    "hf_llm = HuggingFaceInferenceAPI(model_name=\"google/gemma-2-2b-it\", token=hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
    "\n",
    "index = VectorStoreIndex.from_documents(documents=documents, embed_model = embed_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine at 0x7bc5cb14f7d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#query engine\n",
    "\n",
    "query_engine = index.as_query_engine(llm=ollama_llm)\n",
    "query_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "from llama_index.core.llama_pack import download_llama_pack\n",
    "\n",
    "RagEvaluatorPack = download_llama_pack(\"RagEvaluatorPack\", \"./rag_evaluator_pack\")\n",
    "\n",
    "rag_evaluator_pack = RagEvaluatorPack(rag_dataset=rag_dataset, embed_model='local', query_engine=query_engine, judge_llm=ollama_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.evaluation import FaithfulnessEvaluator\n",
    "evaluator_model = FaithfulnessEvaluator(llm=ollama_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_vector = query_engine.query(\"What is the first thing I need to do when I have covid symptoms?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seek medical attention as soon as possible if you experience fever, cough, and difficulty breathing due to COVID-19 symptoms. It's important to call ahead by telephone before visiting a healthcare facility for guidance on the right place of care based on your local situation.\n"
     ]
    }
   ],
   "source": [
    "print(response_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_result = evaluator_model.evaluate_response(response=response_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seek medical attention as soon as possible if you experience fever, cough, and difficulty breathing due to COVID-19 symptoms. It's important to call ahead by telephone before visiting a healthcare facility for guidance on the right place of care based on your local situation.\n"
     ]
    }
   ],
   "source": [
    "print(eval_result.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
